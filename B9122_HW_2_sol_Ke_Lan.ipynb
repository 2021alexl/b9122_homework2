{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://press.un.org/en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_press_release(soup):\n",
    "    press_release_tag = soup.find('a', {'href': '/en/press-release', 'hreflang': 'en'})\n",
    "    if press_release_tag:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_plenary_session(soup):\n",
    "    tag = soup.find('span', class_=\"ep_name\", string=\"Plenary session\")\n",
    "    if tag:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_crisis(soup):\n",
    "    if 'crisis' in soup.get_text().lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_link(link, visited, q):\n",
    "    link_url = link['href']\n",
    "    if link_url.startswith('/'):\n",
    "        if q == 'Q1':\n",
    "            link_url = 'https://press.un.org' + link_url\n",
    "        elif q == 'Q2':\n",
    "            link_url = 'https://www.europarl.europa.eu' + link_url\n",
    "    if not link_url.startswith('#') and link_url not in visited:\n",
    "        return link_url\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_press_release(url, visited, q):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    except requests.RequestException:\n",
    "        return None, []\n",
    "\n",
    "    press_release = None\n",
    "    if q == 'Q1' and is_press_release(soup) and contains_crisis(soup):\n",
    "        press_release = url\n",
    "    elif q == 'Q2' and is_plenary_session(soup) and contains_crisis(soup):\n",
    "        press_release = url\n",
    "\n",
    "    links = []\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        new_link = add_link(link, visited, q)\n",
    "        if new_link:\n",
    "            links.append(new_link)\n",
    "\n",
    "    return press_release, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_press_releases(seed_url, q, print = False):\n",
    "    visited = set()\n",
    "    to_visit = [seed_url]\n",
    "    press_releases = []\n",
    "    max_ = 800\n",
    "    now = 0\n",
    "    while to_visit and len(press_releases) < 10 and now < max_:\n",
    "        url = to_visit.pop(0)\n",
    "        if url in visited:\n",
    "            continue\n",
    "        visited.add(url)\n",
    "        if print == True:\n",
    "            print(url)\n",
    "\n",
    "        press_release, links = find_press_release(url, visited, q)\n",
    "        if press_release:\n",
    "            press_releases.append(press_release)\n",
    "        to_visit.extend(links)\n",
    "        now += 1\n",
    "\n",
    "    return press_releases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/.pyenv/versions/my-project/lib/python3.9/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "urls_1 = get_press_releases('https://press.un.org/en' , 'Q1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://press.un.org/en/2023/sgsm21980.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21978.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21947.doc.htm\n",
      "https://press.un.org/en/2023/dsgsm1874.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21952.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21876.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21852.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21806.doc.htm\n",
      "https://press.un.org/en/2023/dsgsm1848.doc.htm\n",
      "https://press.un.org/en/2023/sgsm21765.doc.htm\n"
     ]
    }
   ],
   "source": [
    "for u in urls_1:\n",
    "    print(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_2 = get_press_releases('https://www.europarl.europa.eu/news/en/press-room', 'Q2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.europarl.europa.eu/news/en/press-room/20230929IPR06132/nagorno-karabakh-meps-demand-review-of-eu-relations-with-azerbaijan\n"
     ]
    }
   ],
   "source": [
    "for u in urls_2:\n",
    "    print(u)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
